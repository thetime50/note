# 2019-9-17-tf-001 教程
## 开始使用 TensorFlow
- [TensorFlow Core](https://tensorflow.google.cn/tutorials/)
- [Colaboratory](https://colab.research.google.com/notebooks/welcome.ipynb)
- [Colab: An easy way to learn and use TensorFlow](https://medium.com/tensorflow/colab-an-easy-way-to-learn-and-use-tensorflow-d74d1686e309)
- [tensorflow youtube](https://www.youtube.com/tensorflow)

- [keras](https://keras.io/zh/)

## 学习和使用机器学习
### 概览
- [Book: Deep Learning with Python](https://books.google.com/books?id=Yo3CAQAACAAJ)
- [机器学习速成课程](https://developers.google.cn/machine-learning/crash-course/)

### 基本分类
[link->](https://tensorflow.google.cn/tutorials/keras/basic_classification)

[开始时使用 TensorFlow](#开始使用-tensorflow)demo

```python
import tensorflow as tf
mnist = tf.keras.datasets.mnist

(x_train, y_train),(x_test, y_test) = mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0 # 调整数据格式 这里是做了运算符重载?

model = tf.keras.models.Sequential([
  tf.keras.layers.Flatten(input_shape=(28, 28)), # 展开图片(二维数组)
  tf.keras.layers.Dense(512, activation=tf.nn.relu), # 512个节点 稠密链接层或全连接层
  tf.keras.layers.Dropout(0.2), # 下降梯度??
  tf.keras.layers.Dense(10, activation=tf.nn.softmax) # 输出节点 softmax回归
])
model.compile(optimizer='adam', # 优化器 
              loss='sparse_categorical_crossentropy', # 损失函数
              metrics=['accuracy']) # 显示的评估结果数据

model.fit(x_train, y_train, epochs=5)
model.evaluate(x_test, y_test)
```


```python
from __future__ import absolute_import, division, print_function, unicode_literals

# 导入TensorFlow和tf.keras
import tensorflow as tf
from tensorflow import keras

# 导入辅助库
import numpy as np
import matplotlib.pyplot as plt

print(tf.__version__)

fashion_mnist = keras.datasets.fashion_mnist

(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()

# 显示图片
plt.figure()
plt.imshow(train_images[0])
plt.colorbar()
plt.grid(False)
plt.show()

#处理图片数据
train_images = train_images / 255.0

test_images = test_images / 255.0
# 显示图片和名称
plt.figure(figsize=(10,10))
for i in range(25):
    plt.subplot(5,5,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(train_images[i], cmap=plt.cm.binary)
    plt.xlabel(class_names[train_labels[i]])
plt.show()

# 配置模型层
model=keras.Sequential([
  keras.layes.Flatten(input_shape=(28,28)),
  keras.layes.Dense(128,activation=tf.nn.relu),
  keras.layes.Dense(10,activation=tf.nn.softmax)
])

model.compile(optimizer='adam',
              loss='spares_categorical_crossentropy',
              metrics=['accuraty'])

model.fit(train_images,train_labels.epochs=5)
test_loss, test_acc=model.evaluste(test_images,test.labels)
print('test accuracy',test_acc,"loss",test_loss)#测试数据精度低于训练精度说明过拟合

# 进行预测
predictions = model.predict(test_iamges[:20])
print(predictions[0],np.argmax(prediction[0]),test_lables[0])

# 图表显示
def plot_image(i,predictions_array,true_label,img):
  predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]
  plt.grid(False)
  plt.xticks([])
  plt.yticks([])

  plt.imshow(img, cmap=plt.cm.binary)

  predicted_label = np.argmax(predictions_array)
  if predicted_label == true_label:
    color = 'blue'
  else:
    color = 'red'
  plt.xlabel("{} {:2.0f} ({})".format(class_names[predicted_label],
                                100*np.max(predictions_array),
                                class_names[true_label]),
                              color=color)

def plot_value_array(i, predictions_array, true_label):
  predictions_array, true_label = predictions_array[i], true_label[i]
  plt.grid(False)
  plt.xticks([])
  plt.yticks([])
  thisplot = plt.bar(range(10), predictions_array, color="#777777")
  plt.ylim([0,1])
  predicted_label = np.argmax(predictions_array)

  thisplot[predicted_label].set_color('red')
  thisplot[true_label].set_color('blue')

i = 0
plt.figure(figsize=(6,3))
plt.subplot(1,2,1)
plot_image(i, predictions, test_labels, test_images)
plt.subplot(1,2,2)
plot_value_array(i, predictions, test_labels)
plt.show()

num_rows=5
num_cols=3
num_images = num_rows*num_cols
plt.figure(figsize=(2*2*num_cols, 2*num_rows))
for i in range(num_images):
  plt.subplot(num_rows, 2*num_cols, 2*i+1)
  plot_image(i, predictions, test_labels, test_images)
  plt.subplot(num_rows, 2*num_cols, 2*i+2)
  plot_value_array(i, predictions, test_labels)
plt.show()

#预测单个数据
img = test_images[0]
img = (np.expand_dims(img,0)) # 包装一下
print(test_images[0],img)
predictions_single = model.predict(img)
print(predictions_single)
plot_value_array(0, predictions_single, test_labels)
plt.xticks(range(10), class_names, rotation=45)
plt.show()
prediction_result = np.argmax(predictions_single[0])
print(prediction_result)
```

### 影评文本分类-tfHub
[link->](https://tensorflow.google.cn/tutorials/keras/text_classification_with_hub)

```python
#!python36
# https://tensorflow.google.cn/tutorials/keras/text_classification_with_hub
from __future__ import absolute_import, division, print_function, unicode_literals

import numpy as np

import tensorflow as tf

import tensorflow_hub as hub
import tensorflow_datasets as tfds

print("Version: ", tf.__version__)
print("Eager mode: ", tf.executing_eagerly())
print("Hub version: ", hub.__version__)
print("GPU is", "available" if tf.config.experimental.list_physical_devices("GPU") else "NOT AVAILABLE")

# 将训练集按照 6:4 的比例进行切割，从而最终我们将得到 15,000
# 个训练样本, 10,000 个验证样本以及 25,000 个测试样本
train_validation_split = tfds.Split.TRAIN.subsplit([6, 4])

(train_data, validation_data), test_data = tfds.load(
    name="imdb_reviews", 
    split=(train_validation_split, tfds.Split.TEST),
    as_supervised=True)

train_examples_batch, train_labels_batch = next(iter(train_data.batch(10)))
train_examples_batch
train_labels_batch

#使用预训练的text embedding文本嵌入模型将文本转换为embedding vectos嵌入向量
embedding = "https://hub.tensorflow.google.cn/google/tf2-preview/gnews-swivel-20dim/1"
# embedding = "google/tf2-preview/gnews-swivel-20dim-with-oov/1" # 2.5%的词汇转换为未登录词桶（OOV buckets）
# embedding = "google/tf2-preview/nnlm-en-dim50/1" # 1M 50维
# embedding = "google/tf2-preview/nnlm-en-dim128/1" # 1M 128维
hub_layer = hub.KerasLayer(embedding, input_shape=[], 
                           dtype=tf.string, trainable=True)
hub_layer(train_examples_batch[:3])

# 模型层
model = tf.keras.Sequential()
model.add(hub_layer)
model.add(tf.keras.layers.Dense(16, activation='relu'))
model.add(tf.keras.layers.Dense(1, activation='sigmoid'))

model.summary()

# 训练
history = model.fit(train_data.shuffle(10000).batch(512),
                    epochs=20,
                    validation_data=validation_data.batch(512),
                    verbose=1)

# 评估
results = model.evaluate(test_data.batch(512), verbose=2)
for name, value in zip(model.metrics_names, results):
  print("%s: %.3f" % (name, value))
```
使用嵌入向量
- 不必自己文本预处理
- 从迁移学习中受益
- 嵌入具有固定长度，更易于处理

### 影评文本分类-预处理文本
[link->](https://tensorflow.google.cn/tutorials/keras/text_classification)

```python
#!python36
# https://tensorflow.google.cn/tutorials/keras/text_classification
import tensorflow as tf
from tensorflow import keras

import numpy as np

print(tf.__version__)

# 加载数据
imdb = keras.datasets.imdb
(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000) # 映射前10000的词
# _data 高频词映射索引
# _labels 0 或 1 负面/正面

word_index = imdb.get_word_index()#单词-索引映射表
word_index = {k:(v+3) for k,v in word_index.items()} #开头带单引号的数据是什么 原本后面的数值是什么
word_index["<PAD>"] = 0
word_index["<START>"] = 1
word_index["<UNK>"] = 2  # unknown
word_index["<UNUSED>"] = 3

reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])

def decode_review(text):
  return ' '.join([reverse_word_index.get(i, '?') for i in text])

#show etxt
# print(decode_review(train_data[0]))

# 影评数组转换为张量
# 标准化数据
train_data = keras.preprocessing.sequence.pad_sequences(train_data,
  value=word_index["<PAD>"],
  padding='post',
  maxlen=256)

test_data = keras.preprocessing.sequence.pad_sequences(test_data,
  value=word_index["<PAD>"],
  padding='post',
  maxlen=256)

  # input shape is the vocabulary count used for the movie reviews (10,000 words)
vocab_size = 10000

model = keras.Sequential()
model.add(keras.layers.Embedding(vocab_size, 16)) # 将单词索引转换到向量空间
model.add(keras.layers.GlobalAveragePooling1D()) # AGP 全局平均池化 减少数据量获取特征图从而减少过拟合
model.add(keras.layers.Dense(16, activation=tf.nn.relu)) # 隐藏层 全链接层
model.add(keras.layers.Dense(1, activation=tf.nn.sigmoid))

model.summary()

# 损失函数和优化器
model.compile(optimizer=tf.train.AdamOptimizer(),
              loss='binary_crossentropy', #二分类交叉熵 # mean_squared_error #均方差
              metrics=['accuracy'])

# 验证集
x_val = train_data[:10000]
partial_x_train = train_data[10000:]

y_val = train_labels[:10000]
partial_y_train = train_labels[10000:]

# 训练
history = model.fit(partial_x_train,
                    partial_y_train,
                    epochs=40,
                    batch_size=512,# 批大小?
                    validation_data=(x_val, y_val),# 测试数据
                    verbose=1) # 冗余?
# 评估
results = model.evaluate(test_data, test_labels)
print(results)

# 训练过程信息
history_dict = history.history
history_dict.keys()

import matplotlib.pyplot as plt

acc = history.history['acc']
val_acc = history.history['val_acc']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(1, len(acc) + 1)
# loss图表 过拟合后测试集的损失函数结果计算结果升高
# "bo" is for "blue dot"
plt.plot(epochs, loss, 'bo', label='Training loss')
# b is for "solid blue line"
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

plt.show()
# 准确性图表
plt.clf()   # clear figure
acc_values = history_dict['acc']
val_acc_values = history_dict['val_acc']

plt.plot(epochs, acc, 'bo', label='Training acc')
plt.plot(epochs, val_acc, 'b', label='Validation acc')
plt.title('Training and validation accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

plt.show()
```