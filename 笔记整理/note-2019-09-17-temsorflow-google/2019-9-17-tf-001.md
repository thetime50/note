# 2019-9-17-tf-001 教程
## 开始使用 TensorFlow
- [TensorFlow Core](https://tensorflow.google.cn/tutorials/)
- [Colaboratory](https://colab.research.google.com/notebooks/welcome.ipynb)
- [Colab: An easy way to learn and use TensorFlow](https://medium.com/tensorflow/colab-an-easy-way-to-learn-and-use-tensorflow-d74d1686e309)
- [tensorflow youtube](https://www.youtube.com/tensorflow)

- [keras](https://keras.io/zh/)

## 学习和使用机器学习
### 概览
- [Book: Deep Learning with Python](https://books.google.com/books?id=Yo3CAQAACAAJ)
- [机器学习速成课程](https://developers.google.cn/machine-learning/crash-course/)

### 基本分类
[link->](https://tensorflow.google.cn/tutorials/keras/basic_classification)

[开始时使用 TensorFlow](#开始使用-tensorflow)demo

```python
import tensorflow as tf
mnist = tf.keras.datasets.mnist

(x_train, y_train),(x_test, y_test) = mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0 # 调整数据格式 这里是做了运算符重载?

model = tf.keras.models.Sequential([
  tf.keras.layers.Flatten(input_shape=(28, 28)), # 展开图片(二维数组)
  tf.keras.layers.Dense(512, activation=tf.nn.relu), # 512个节点 稠密链接层或全连接层
  tf.keras.layers.Dropout(0.2), # 下降梯度??
  tf.keras.layers.Dense(10, activation=tf.nn.softmax) # 输出节点 softmax回归
])
model.compile(optimizer='adam', # 优化器 
              loss='sparse_categorical_crossentropy', # 损失函数
              metrics=['accuracy']) # 显示的评估结果数据

model.fit(x_train, y_train, epochs=5)
model.evaluate(x_test, y_test)
```


```python
from __future__ import absolute_import, division, print_function, unicode_literals

# 导入TensorFlow和tf.keras
import tensorflow as tf
from tensorflow import keras

# 导入辅助库
import numpy as np
import matplotlib.pyplot as plt

print(tf.__version__)

fashion_mnist = keras.datasets.fashion_mnist

(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()

# 显示图片
plt.figure()
plt.imshow(train_images[0])
plt.colorbar()
plt.grid(False)
plt.show()

#处理图片数据
train_images = train_images / 255.0

test_images = test_images / 255.0
# 显示图片和名称
plt.figure(figsize=(10,10))
for i in range(25):
    plt.subplot(5,5,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(train_images[i], cmap=plt.cm.binary)
    plt.xlabel(class_names[train_labels[i]])
plt.show()

# 配置模型层
model=keras.Sequential([
  keras.layes.Flatten(input_shape=(28,28)),
  keras.layes.Dense(128,activation=tf.nn.relu),
  keras.layes.Dense(10,activation=tf.nn.softmax)
])

model.compile(optimizer='adam',
              loss='spares_categorical_crossentropy',
              metrics=['accuraty'])

model.fit(train_images,train_labels.epochs=5)
test_loss, test_acc=model.evaluste(test_images,test.labels)
print('test accuracy',test_acc,"loss",test_loss)#测试数据精度低于训练精度说明过拟合

# 进行预测
predictions = model.predict(test_iamges[:20])
print(predictions[0],np.argmax(prediction[0]),test_lables[0])

# 图表显示
def plot_image(i,predictions_array,true_label,img):
  predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]
  plt.grid(False)
  plt.xticks([])
  plt.yticks([])

  plt.imshow(img, cmap=plt.cm.binary)

  predicted_label = np.argmax(predictions_array)
  if predicted_label == true_label:
    color = 'blue'
  else:
    color = 'red'
  plt.xlabel("{} {:2.0f} ({})".format(class_names[predicted_label],
                                100*np.max(predictions_array),
                                class_names[true_label]),
                              color=color)

def plot_value_array(i, predictions_array, true_label):
  predictions_array, true_label = predictions_array[i], true_label[i]
  plt.grid(False)
  plt.xticks([])
  plt.yticks([])
  thisplot = plt.bar(range(10), predictions_array, color="#777777")
  plt.ylim([0,1])
  predicted_label = np.argmax(predictions_array)

  thisplot[predicted_label].set_color('red')
  thisplot[true_label].set_color('blue')

i = 0
plt.figure(figsize=(6,3))
plt.subplot(1,2,1)
plot_image(i, predictions, test_labels, test_images)
plt.subplot(1,2,2)
plot_value_array(i, predictions, test_labels)
plt.show()

num_rows=5
num_cols=3
num_images = num_rows*num_cols
plt.figure(figsize=(2*2*num_cols, 2*num_rows))
for i in range(num_images):
  plt.subplot(num_rows, 2*num_cols, 2*i+1)
  plot_image(i, predictions, test_labels, test_images)
  plt.subplot(num_rows, 2*num_cols, 2*i+2)
  plot_value_array(i, predictions, test_labels)
plt.show()

#预测单个数据
img = test_images[0]
img = (np.expand_dims(img,0)) # 包装一下
print(test_images[0],img)
predictions_single = model.predict(img)
print(predictions_single)
plot_value_array(0, predictions_single, test_labels)
plt.xticks(range(10), class_names, rotation=45)
plt.show()
prediction_result = np.argmax(predictions_single[0])
print(prediction_result)
```

### 影评文本分类-tfHub
[link->](https://tensorflow.google.cn/tutorials/keras/text_classification_with_hub)

```python
#!python36
# https://tensorflow.google.cn/tutorials/keras/text_classification_with_hub
from __future__ import absolute_import, division, print_function, unicode_literals

import numpy as np

import tensorflow as tf

import tensorflow_hub as hub
import tensorflow_datasets as tfds

print("Version: ", tf.__version__)
print("Eager mode: ", tf.executing_eagerly())
print("Hub version: ", hub.__version__)
print("GPU is", "available" if tf.config.experimental.list_physical_devices("GPU") else "NOT AVAILABLE")

# 将训练集按照 6:4 的比例进行切割，从而最终我们将得到 15,000
# 个训练样本, 10,000 个验证样本以及 25,000 个测试样本
train_validation_split = tfds.Split.TRAIN.subsplit([6, 4])

(train_data, validation_data), test_data = tfds.load(
    name="imdb_reviews", 
    split=(train_validation_split, tfds.Split.TEST),
    as_supervised=True)

train_examples_batch, train_labels_batch = next(iter(train_data.batch(10)))
train_examples_batch
train_labels_batch

#使用预训练的text embedding文本嵌入模型将文本转换为embedding vectos嵌入向量
embedding = "https://hub.tensorflow.google.cn/google/tf2-preview/gnews-swivel-20dim/1"
# embedding = "google/tf2-preview/gnews-swivel-20dim-with-oov/1" # 2.5%的词汇转换为未登录词桶（OOV buckets）
# embedding = "google/tf2-preview/nnlm-en-dim50/1" # 1M 50维
# embedding = "google/tf2-preview/nnlm-en-dim128/1" # 1M 128维
hub_layer = hub.KerasLayer(embedding, input_shape=[], 
                           dtype=tf.string, trainable=True)
hub_layer(train_examples_batch[:3])

# 模型层
model = tf.keras.Sequential()
model.add(hub_layer)
model.add(tf.keras.layers.Dense(16, activation='relu'))
model.add(tf.keras.layers.Dense(1, activation='sigmoid'))

model.summary()

# 训练
history = model.fit(train_data.shuffle(10000).batch(512),
                    epochs=20,
                    validation_data=validation_data.batch(512),
                    verbose=1)

# 评估
results = model.evaluate(test_data.batch(512), verbose=2)
for name, value in zip(model.metrics_names, results):
  print("%s: %.3f" % (name, value))
```
使用嵌入向量
- 不必自己文本预处理
- 从迁移学习中受益 （正交的维度空间，互相关联）
- 嵌入具有固定长度，更易于处理

### 影评文本分类-预处理文本
[link->](https://tensorflow.google.cn/tutorials/keras/text_classification)

```python
#!python36
# https://tensorflow.google.cn/tutorials/keras/text_classification
import tensorflow as tf
from tensorflow import keras

import numpy as np

print(tf.__version__)

# 加载数据
imdb = keras.datasets.imdb
(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000) # 映射前10000的词
# _data 高频词映射索引
# _labels 0 或 1 负面/正面

word_index = imdb.get_word_index()#单词-索引映射表
word_index = {k:(v+3) for k,v in word_index.items()} #开头带单引号的数据是什么 原本后面的数值是什么
word_index["<PAD>"] = 0
word_index["<START>"] = 1
word_index["<UNK>"] = 2  # unknown
word_index["<UNUSED>"] = 3

reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])

def decode_review(text):
  return ' '.join([reverse_word_index.get(i, '?') for i in text])

#show etxt
# print(decode_review(train_data[0]))

# 影评数组转换为张量
# 标准化数据
train_data = keras.preprocessing.sequence.pad_sequences(train_data,
  value=word_index["<PAD>"],
  padding='post',
  maxlen=256)

test_data = keras.preprocessing.sequence.pad_sequences(test_data,
  value=word_index["<PAD>"],
  padding='post',
  maxlen=256)

  # input shape is the vocabulary count used for the movie reviews (10,000 words)
vocab_size = 10000

model = keras.Sequential()
model.add(keras.layers.Embedding(vocab_size, 16)) # 将单词索引转换到向量空间
model.add(keras.layers.GlobalAveragePooling1D()) # AGP 全局平均池化 减少数据量获取特征图从而减少过拟合
model.add(keras.layers.Dense(16, activation=tf.nn.relu)) # 隐藏层 全链接层
model.add(keras.layers.Dense(1, activation=tf.nn.sigmoid))

model.summary()

# 损失函数和优化器
model.compile(optimizer=tf.train.AdamOptimizer(),
              loss='binary_crossentropy', #二分类交叉熵 # mean_squared_error #均方差
              metrics=['accuracy'])

# 验证集
x_val = train_data[:10000]
partial_x_train = train_data[10000:]

y_val = train_labels[:10000]
partial_y_train = train_labels[10000:]

# 训练
history = model.fit(partial_x_train,
                    partial_y_train,
                    epochs=40,
                    batch_size=512,# 批大小?
                    validation_data=(x_val, y_val),# 测试数据
                    verbose=1) # 冗余?
# 评估
results = model.evaluate(test_data, test_labels)
print(results)

# 训练过程信息
history_dict = history.history
history_dict.keys()

import matplotlib.pyplot as plt

acc = history.history['acc']
val_acc = history.history['val_acc']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(1, len(acc) + 1)
# loss图表 过拟合后测试集的损失函数结果计算结果升高
# "bo" is for "blue dot"
plt.plot(epochs, loss, 'bo', label='Training loss')
# b is for "solid blue line"
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

plt.show()
# 准确性图表
plt.clf()   # clear figure
acc_values = history_dict['acc']
val_acc_values = history_dict['val_acc']

plt.plot(epochs, acc, 'bo', label='Training acc')
plt.plot(epochs, val_acc, 'b', label='Validation acc')
plt.title('Training and validation accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

plt.show()
```

### 回归问题
Basic regression: Predict fuel efficiency
```python
#!python36
# https://tensorflow.google.cn/tutorials/keras/regression
from __future__ import absolute_import, division, print_function, unicode_literals

import pathlib

import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns

import tensorflow as tf

from tensorflow import keras
from tensorflow.keras import layers

print(tf.__version__)

dataset_path = keras.utils.get_file("auto-mpg.data", "http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data")
# dataset_path

column_names = ['MPG','Cylinders','Displacement','Horsepower','Weight',
                'Acceleration', 'Model Year', 'Origin']
raw_dataset = pd.read_csv(dataset_path, names=column_names,
                      na_values = "?", comment='\t',
                      sep=" ", skipinitialspace=True)

dataset = raw_dataset.copy()
# dataset.tail()
# dataset.isna().sum()
dataset = dataset.dropna() # 删除空数据行
origin = dataset.pop('Origin') # 获取Origin列数据
dataset['USA'] = (origin == 1)*1.0 # 转为one hot编码
dataset['Europe'] = (origin == 2)*1.0
dataset['Japan'] = (origin == 3)*1.0
# dataset.tail()

# 拆分训练数据和测试数据
train_dataset = dataset.sample(frac=0.8,random_state=0)
test_dataset = dataset.drop(train_dataset.index)
# 查看数据
sns.pairplot(train_dataset[["MPG", "Cylinders", "Displacement", "Weight"]], diag_kind="kde")
plt.show()

train_stats = train_dataset.describe()
train_stats.pop("MPG")
train_stats = train_stats.transpose()
train_stats
# 分离特征值
train_labels = train_dataset.pop('MPG')
test_labels = test_dataset.pop('MPG')
# 数据规范化
def norm(x):
  return (x - train_stats['mean']) / train_stats['std']
normed_train_data = norm(train_dataset)
normed_test_data = norm(test_dataset)
# 构建模型
def build_model():
  model = keras.Sequential([
    layers.Dense(64, activation='relu', input_shape=[len(train_dataset.keys())]),
    layers.Dense(64, activation='relu'),
    layers.Dense(1)
  ])

  optimizer = tf.keras.optimizers.RMSprop(0.001)

  model.compile(loss='mse',
                optimizer=optimizer,
                metrics=['mae', 'mse'])
  return model

model = build_model()
# model.summary() # 显示模型定义
# 预测
example_batch = normed_train_data[:10]
example_result = model.predict(example_batch)
example_result

# 通过为每个完成的时期打印一个点来显示训练进度
class PrintDot(keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs):
    if epoch % 100 == 0: print('')
    print('.', end='')

EPOCHS = 1000
# 训练模型
history = model.fit(
  normed_train_data, train_labels,
  epochs=EPOCHS, validation_split = 0.2, verbose=0,
  callbacks=[PrintDot()])

hist = pd.DataFrame(history.history)
hist['epoch'] = history.epoch
hist.tail()

def plot_history(history):
  hist = pd.DataFrame(history.history)
  hist['epoch'] = history.epoch

  plt.figure()
  plt.xlabel('Epoch')
  plt.ylabel('Mean Abs Error [MPG]')
  plt.plot(hist['epoch'], hist['mae'],
           label='Train Error')
  plt.plot(hist['epoch'], hist['val_mae'],
           label = 'Val Error')
  plt.ylim([0,5])
  plt.legend()

  plt.figure()
  plt.xlabel('Epoch')
  plt.ylabel('Mean Square Error [$MPG^2$]')
  plt.plot(hist['epoch'], hist['mse'],
           label='Train Error')
  plt.plot(hist['epoch'], hist['val_mse'],
           label = 'Val Error')
  plt.ylim([0,20])
  plt.legend()
  plt.show()

# plot_history(history)

# 用测试集评估模型
loss, mae, mse = model.evaluate(normed_test_data, test_labels, verbose=2)

print("Testing set Mean Abs Error: {:5.2f} MPG".format(mae))

# 预测数据
test_predictions = model.predict(normed_test_data).flatten()

plt.scatter(test_labels, test_predictions)
plt.xlabel('True Values [MPG]')
plt.ylabel('Predictions [MPG]')
plt.axis('equal')
plt.axis('square')
plt.xlim([0,plt.xlim()[1]])
plt.ylim([0,plt.ylim()[1]])
_ = plt.plot([-100, 100], [-100, 100])
plt.show()
# 误差分布
error = test_predictions - test_labels
plt.hist(error, bins = 25)
plt.xlabel("Prediction Error [MPG]")
_ = plt.ylabel("Count")
plt.show()
```

- 均方误差（MSE）是用于回归问题的常见损失函数（分类问题中使用不同的损失函数（交叉熵））。
- 类似的，用于回归的评估指标与分类不同。 常见的回归指标是平均绝对误差（MAE）（分类问题accuracy）。
- 当数字输入数据特征的值存在不同范围时，每个特征应独立缩放到相同范围。
- 如果训练数据不多，一种方法是选择隐藏层较少的小网络，以避免过度拟合。
- 早期停止是一种防止过度拟合的有效技术。