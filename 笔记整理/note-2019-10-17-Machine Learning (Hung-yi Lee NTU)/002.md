## 2 Where does the error come from
[ML Lecture 2: Where does the error come from?](https://www.youtube.com/watch?v=D_S6y0Jm6dQ&list=PLJV_el3uVTsPy9oCRY30oBPNLCo89yu49&index=5)  
[pdf](http://speech.ee.ntu.edu.tw/~tlkagk/courses/ML_2016/Lecture/Bias%20and%20Variance%20(v2).pdf)

真实的关系<img src="https://latex.codecogs.com/gif.latex?\bg_white&space;\hat&space;y=\hat&space;f(pokemon)" title="\hat y=\hat f(pokemon)" />

预测值f<sup>*</sup>

L 来自 Bias + Variance  
(偏差和方差?)
准确度 数据中心 和 离散程度


- 对于变量x
  - 假设对于变量x的平均值为<img src="https://latex.codecogs.com/gif.latex?\bg_white&space;\mu" title="\mu" />
  - 假设对于变量x方差为<img src="https://latex.codecogs.com/gif.latex?\bg_white&space;\sigma^2" title="\sigma^2" />

- 估测平均值<img src="https://latex.codecogs.com/gif.latex?\bg_white&space;\mu" title="\mu" />
  - 收集N个样本<img src="https://latex.codecogs.com/gif.latex?\bg_white&space;\mu" title="\mu" />  
  样本平均值<img src="https://latex.codecogs.com/gif.latex?\bg_white&space;m=\frac{1}{n}\sum_n{x^n}\neq\mu" title="m=\frac{1}{n}\sum_n{x^n}\neq\mu" />  
  期望<img src="https://latex.codecogs.com/gif.latex?\bg_white&space;E[m]=E[\frac{1}{N}\sum_n&space;x^n]=\frac{1}{n}\sum_n{E[x^n]}=\mu" title="E[m]=E[\frac{1}{N}\sum_n x^n]=\frac{1}{n}\sum_n{E[x^n]}=\mu" />  
  Variance方差：<img src="https://latex.codecogs.com/gif.latex?\bg_white&space;Var[m]=\frac{\sigma^2}{N}" title="Var[m]=\frac{\sigma^2}{N}" /> ??
  样本方差 <img src="https://latex.codecogs.com/gif.latex?\bg_white&space;s^2=\frac{1}{,}\sum{(x^n-m)}^2" title="s^2=\frac{1}{,}\sum{(x^n-m)}^2" />?  
  方差的期望<img src="https://latex.codecogs.com/gif.latex?\bg_white&space;E[s^2]=\frac{N-1}{N}\sigma^2\neq\sigma^2" title="E[s^2]=\frac{N-1}{N}\sigma^2\neq\sigma^2" />样本方差整体小于实际方差

模型越复杂 可能性越多 同样的样本量计算得可能的模型也会越分散，使用复杂模型拟合数据更可能接近真实数据(mean)但是方差也容易偏大(variance)  
用简单模型拟合数据，得到的模型之间比较一致(veriance)，但是和真实数据容易有偏差(mean)

所以xx方法是倾向于选择更简单的模型，数据量小时倾向于使用简单的模型，真实模型复杂时要数据量够大才选择复杂模型

### 分析模型结果

#### bias 和 veriance

- Underfitting error来自于比较的的Bias  
  Training data 不完全拟合
- Overfitting error来自于比较大的Variance  
  Training data 能完全拟合 Testing data 上的误差过大

平衡bias和Variance后
- bias大时怎么处理
  - 重新设计模型 增加输入变量特征
  - 增加模型复杂度
- variance大怎么处理
  - 增加实际数据 或者利用已有资源生成数据
  - 正则化(也可能损失bias)


### 交叉验证
Cross Validation

选择最终模型时平衡bias 和variance  
最后注意以下问题

用测试集得到的最小error不等于真实的error(测试集本身是有偏差和其他一些特征的)

example data
|- Testing data
|- Training set
    |-Tarining set
    |-Validation set

用T-V数据训练出多个模型 选出error最好的模型
再用所有数据再次进行训练这模型 

test data的error一般会大于Validation data的error 但是会更接近实际的error

不要再用test error的结果回去调整模型 test error只是作为呈现效果结果的一个参考，用test error调整模型 模型会被过渡的带入test error 的特征。

#### N-fold Cross Validation
N折交叉验证
Training data 分组轮流作为验证集 取每次不同Validation的平均数