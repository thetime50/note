## 21-2 Recurrent Neural Network (Part II)
[21-2 Recurrent Neural Network (Part II)](https://www.youtube.com/watch?v=rTqmWlnwz_0&list=PLJV_el3uVTsPy9oCRY30oBPNLCo89yu49&index=31)  
[pdf](http://speech.ee.ntu.edu.tw/~tlkagk/courses/ML_2016/Lecture/RNN%20(v2).pdf)

### RNN 如何learning

Recurrent Neural Network (RNN) 要如何做 learnint

要定一个cost function,evaluate model 的parameter 好坏。

给word sequence 做 slot filling 时输入顺序不能打乱  
每一个时间点 RNN output 和 reference vector 的 cross entropy 和就是loss

依然是 gradient descent 

在LSTM 中做gradient descent 的技巧: Backpropagation Through Time (BPTT)  
因为RNN 要考虑time sequence 问题（某一时刻的输出会有之前数据和参数和影响）

RNN 的training 是比较困难的  