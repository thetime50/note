##  11 Why Deep
[11 Why Deep](https://www.youtube.com/watch?v=XsC9byQkUH8&list=PLJV_el3uVTsPy9oCRY30oBPNLCo89yu49&index=20)

比较deep&Shallow的model时要注意控制两者参数一样多

shallow的模型即使参数和deep的量一样，shallow的正确率也会差一些

**模组化** 可以共用上一层layer的output  
classifier的数据可以共用 所以deep learning使用的train data的数据量较少

big data直接使用table lookup

### modularization speech
<pre>
        speech
          &downarrow;
      phoneme(音素)
          &downarrow;
       tri-phone
(一个phoneme在不同的前后phoneme时发音的差异)
     &swarrow;   &downarrow;   &searrow;
state1  state2  state3
</pre>

大致流程
<pre>
input: acoustic feature(wave form window)
      &downarrow; (Classification)
  output: state
      &downarrow;
    phoneme
      &downarrow;
     word
</pre>

在deep learning之前的做法  
**HMM-GMM**

假设state的acoustic feature是stationary的，用GMM来描述  
但是中英文都有30+的phoneme，每个phoneme的context不同有30<sup>3</sup>个tri-phone，每个tri-phone有3个state，每个state都用GMM模型描述  
所以相近的state共用model-distribution ->***tied-state***

**subspace GMM**  
先从数据中提取出Gaussian distribution pool  
state从Gaussian pool里挑选model描述自己(使用training data匹配state 和 Gaussian model)

HMM-GMM对state的处理是独立的  
而state的发言之间是和舌头 嘴型有关的


deep learning模组化的特性，可以所以使用较少的参数 不容易over fitting 使用较少的training data

### More Analogy Experiment
Underfitting 时同样的参数数量的模型，1 hidden layer的模型崩坏结果没什么规律，duohidden layer的 崩坏的结果比较规律 模型正确率较高一些(对有规律的结果更可能匹配)。

### End-to-end Learning
只给input和output，中间的各层的function要做什么样的事情由model自己去学习

### shallow learning for Speech

<pre>
    waveform
       &downarrow;
      DFP
       &downarrow;spectrogram
    filter bank
(模拟人类听觉器官得到的filter)
       &downarrow;
      log
       &downarrow;
      dct
       &downarrow;MFCC
    GMM(or DNN)
       &downarrow;
      text
</pre>
可以从 log 开始或者从 spectrogram 开始用 Deep learning 替代，以得到更好的结果


google用很大的Network替代Feature transform最终效果也差不多  
(所以 Fourier transform 是最最基础的操作吧)

### image
<pre>
      img
       &downarrow;
  feature extr
       &downarrow;
    encoding
       &downarrow;
     pooling
       &downarrow;
 classification
       &downarrow;
  output class
</pre>


关于一层hidden layer可以实现所有模型的问题  
如果使用同样的参数数量，用多层模型的结果label去训练单层的模型，单层模型结果是可以逼近多层结果的