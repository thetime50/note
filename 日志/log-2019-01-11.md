# 2019-01-11

## TF初探
[tensorflow-zh](https://github.com/jikexueyuanwiki/tensorflow-zh/blob/master/TOC.md)

### MNIST入门
[link](http://wiki.jikexueyuan.com/project/tensorflow-zh/tutorials/mnist_beginners.html)

展平图片会丢失二维信息，所以这样并不理想，但是暂时并不考虑。
<u>数据集</u>被分成两部分：60000行的训练数据集（mnist.train）和10000行的测试数据集（mnist.test）。在机器学习模型设计时必须有一个单独的测试数据集不用于训练而是用来评估这个模型的性能，从而把设计的模型推广到其他数据集上（**泛化**）。
每一个MNIST数据单元有两部分<u>组成</u>：我们把图片设为“xs”，把对应的标签设为“ys”
MNIST<u>训练数据集</u>中，mnist.train.images 是一个形状为 [60000, 784] 的张量，第一个维度数字用来索引图片，第二个维度数字用来索引每张图片中的像素点。在此张量里的每一个元素，都表示某张图片里的某个像素的强度值，值介于0和1之间。
<u>标签数据</u>是"one-hot vectors"。 一个one-hot向量除了某一位的数字是1以外其余各维度数字都是0。所以在此教程中，数字n将表示成一个只有在第n维度（从0开始）数字为1的10维向量。比如，标签0将表示成([1,0,0,0,0,0,0,0,0,0,0])

- softmax回归
softmax模型可以用来给不同的对象分配概率，即使使用其他模型，通常最后一步也需要用softmax来分配概率。

logistic分布和logistic回归有什么区别。logistic回归如何定义

---
[回归模型](https://baike.baidu.com/item/%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B/4425684)

*分析数据建模归类的方法*
回归模型（regression model）对统计关系进行定量描述的一种数学模型。如多元线性回归的数学模型可以表示为y=β0+β1\*x+εi，
式中:
β0，β1，…，βp是p+1个待估计的参数，
εi是相互独立且服从同一正态分布N(0,σ2)的<u>随机变量(偏差)</u>，
y是随机变量；
x可以是随机变量，也可以是非随机变量,
βi称为<u>回归系数</u>，表征自变量对因变量影响的程度。

**回归模型**是一种预测性的建模技术，它研究的是因变量（目标）和自变量（预测器）之间的关系。这种技术通常用于预测分析，时间序列模型以及发现变量之间的因果关系。

回归模型重要的基础或者方法就是回归分析，回归分析是研究一个变量（被解释变量）关于另一个（些）变量（解释变量）的具体依赖关系的计算方法和理论，是建模和分析数据的重要工具。回归分析的几种常用方法 包含：
1. Linear Regression线性回归
线性回归使用最佳的拟合直线（也就是回归线）在因变量（Y）和一个或多个自变量（X）之间建立一种关系。
用一个方程式来表示它，即
![linear](img/log-2019-01-11/linear.jpg)
其中a表示截距，
b表示直线的斜率，
e是误差项。
这个方程可以根据给定的预测变量（s）来预测目标变量的值。
2. Logistic Regression逻辑回归
逻辑回归是用来计算“事件=Success”和“事件=Failure”的概率。当因变量的类型属于二元（1 / 0，真/假，是/否）变量时，我们就应该使用逻辑回归。这里，Y的值从0到1，它可以用下方程表示。
![logistic](img/log-2019-01-11/logistic.jpg)
上述式子中，p表述具有某个特征的概率。
> 输入值为(-∞,+∞)时，输出(即结果为真的概率)。
自变量接近-∞时为真的概率极小
自变量接近+∞时为真的概率极大
自变量在边缘时概率在两者之间
3. Polynomial Regression多项式回归
4. ...



---
 - [ ] TF
 - [ ] 油猴
